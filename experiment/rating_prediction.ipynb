{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Baseline for Rating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
    "from surprise.accuracy import rmse, mae\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN RATING PREDICTION\n",
    "\n",
    "train=pd.read_csv('/kaggle/input/diss-train/data.train.csv') #Entire dataset of nine domains\n",
    "test=pd.read_csv('/kaggle/input/diss-train/data.test.csv')\n",
    "\n",
    "item_mean = train.groupby('parent_asin')['rating'].mean()\n",
    "\n",
    "# Predict ratings for the test set using item mean\n",
    "test['predicted_rating'] = test['parent_asin'].map(item_mean)\n",
    "\n",
    "# Handle NaN values by filling with the overall mean rating\n",
    "overall_mean = train['rating'].mean()\n",
    "test['predicted_rating'].fillna(overall_mean, inplace=True)\n",
    "\n",
    "# Ensure predicted ratings are integers\n",
    "test['predicted_rating'] = test['predicted_rating'].round().astype(int)\n",
    "\n",
    "rmse = mean_squared_error(test['rating'], test['predicted_rating'], squared=False)\n",
    "mae = mean_absolute_error(test['rating'], test['predicted_rating'])\n",
    "\n",
    "print(f'Baseline Model RMSE: {rmse:.4f}')\n",
    "print(f'Baseline Model MAE: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PMF Method\n",
    "\n",
    "# Define the reader with the appropriate rating scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the data from the DataFrame\n",
    "train_data = Dataset.load_from_df(train[['user_id', 'parent_asin', 'rating']], reader)\n",
    "test_data = Dataset.load_from_df(test[['user_id', 'parent_asin', 'rating']], reader)\n",
    "\n",
    "trainset = train_data.build_full_trainset()\n",
    "\n",
    "testset = test_data.construct_testset(test_data.raw_ratings)\n",
    "\n",
    "pmf = SVD()\n",
    "\n",
    "pmf.fit(trainset)\n",
    "\n",
    "predictions = pmf.test(testset)\n",
    "\n",
    "pmf_rmse = accuracy.rmse(predictions)\n",
    "pmf_mae = accuracy.mae(predictions)\n",
    "\n",
    "print(f'PMF Model RMSE: {pmf_rmse:.4f}')\n",
    "print(f'PMF Model MAE: {pmf_mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ST5 + MLP Implementation for Rating Predicition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKING EMBEDDINGS User embedding concat with item embedding\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/exports/eddie/scratch/s2550585/huggingface_cache/transformers'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/exports/eddie/scratch/s2550585/huggingface_cache/datasets'\n",
    "os.environ['HF_HOME'] = '/exports/eddie/scratch/s2550585/huggingface_cache'\n",
    "\n",
    "def load_data(split, output_dir, domain, seed=36):\n",
    "    print(f\"Processing {split} split...\")\n",
    "    df = pd.read_csv(os.path.join(output_dir, f'{domain}.{split}.csv'))\n",
    "    df = df.groupby('category', group_keys=False).apply(lambda x: x.sample(frac=1, random_state=seed))\n",
    "    df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_and_process_data(df, st_model, device):\n",
    "    users = list(df['history_text']) #user text\n",
    "    items = list(df['target_item_text']) #item text\n",
    "    ratings = torch.tensor(df['rating'].values, dtype=torch.float)  # Ensure ratings are float for regression\n",
    "    \n",
    "    print(\"Encoding user and item data...\")\n",
    "    users_emb = st_model.encode(users, convert_to_tensor=True,show_progress_bar=True)\n",
    "    items_emb = st_model.encode(items, convert_to_tensor=True,show_progress_bar=True)\n",
    "    \n",
    "    combined_emb = torch.cat([users_emb, items_emb], dim=1).to(device)\n",
    "    \n",
    "    return combined_emb, ratings\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "data_path = '/exports/eddie/scratch/s2550585/diss/dataset3/dataset'\n",
    "domain = 'data'\n",
    "train_df = load_data(\"train\", data_path, domain)\n",
    "test_df = load_data(\"test\", data_path, domain)\n",
    "valid_df = load_data(\"valid\", data_path, domain)\n",
    "\n",
    "\n",
    "print(\"Loading SentenceTransformer model...\")\n",
    "st_model = SentenceTransformer('sentence-transformers/sentence-t5-base', device=device)\n",
    "\n",
    "train_combined_emb, train_ratings = load_and_process_data(train_df, st_model, device)\n",
    "valid_combined_emb, valid_ratings = load_and_process_data(valid_df, st_model, device)\n",
    "test_combined_emb, test_ratings = load_and_process_data(test_df, st_model, device)\n",
    "\n",
    "\n",
    "saving_path = '/exports/eddie/scratch/s2550585/rating/data'\n",
    "if not os.path.exists(saving_path):\n",
    "    os.makedirs(saving_path)\n",
    "\n",
    "#Saving the embeddings and ratings\n",
    "torch.save(train_combined_emb, f'{saving_path}/train_combined_emb.pt')\n",
    "torch.save(train_ratings, f'{saving_path}/train_ratings.pt')\n",
    "torch.save(valid_combined_emb, f'{saving_path}/valid_combined_emb.pt')\n",
    "torch.save(valid_ratings, f'{saving_path}/valid_ratings.pt')\n",
    "torch.save(test_combined_emb, f'{saving_path}/test_combined_emb.pt')\n",
    "torch.save(test_ratings, f'{saving_path}/test_ratings.pt')\n",
    "\n",
    "\n",
    "print(\"Embeddings and ratings saved successfully!\")\n",
    "\n",
    "#New Model\n",
    "print(\"loading ST5-Final Model...\")\n",
    "st_model = SentenceTransformer('/exports/eddie/scratch/s2550585/diss/dataset/data/seq-item-eddie/best_model-seq-item-eddie', device=device)\n",
    "\n",
    "train_combined_emb, train_ratings = load_and_process_data(train_df, st_model, device)\n",
    "valid_combined_emb, valid_ratings = load_and_process_data(valid_df, st_model, device)\n",
    "test_combined_emb, test_ratings = load_and_process_data(test_df, st_model, device)\n",
    "\n",
    "#Saving the embeddings and ratings\n",
    "torch.save(train_combined_emb, f'{saving_path}/train_combined_emb_new.pt')\n",
    "torch.save(train_ratings, f'{saving_path}/train_ratings_new.pt')\n",
    "torch.save(valid_combined_emb, f'{saving_path}/valid_combined_emb_new.pt')\n",
    "torch.save(valid_ratings, f'{saving_path}/valid_ratings_new.pt')\n",
    "torch.save(test_combined_emb, f'{saving_path}/test_combined_emb_new.pt')\n",
    "torch.save(test_ratings, f'{saving_path}/test_ratings_new.pt')\n",
    "\n",
    "print(\"Embeddings and ratings saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rating Prediciton using embeddings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class RatingModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RatingModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size, input_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(768),\n",
    "            nn.Linear(768, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 1) \n",
    "        )\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "        return self.model(embeddings).squeeze(1)\n",
    "    \n",
    "\n",
    "class UserItemDataset(Dataset):\n",
    "    def __init__(self, embeddings, ratings):\n",
    "        self.embeddings = embeddings\n",
    "        self.ratings = ratings.float()  # Ensure ratings are float for regression\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.ratings[idx]\n",
    "    \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "num_epochs = 100\n",
    "metric_to_monitor = 'rmse'\n",
    "\n",
    "# Load the embedding for the variant of ST5 Model  \n",
    "print(\"ST5 MODEL\") \n",
    "\n",
    "train_combined_emb=torch.load('/exports/eddie/scratch/s2550585/rating/data/train_combined_emb.pt')\n",
    "train_ratings=torch.load('/exports/eddie/scratch/s2550585/rating/data/train_ratings.pt')\n",
    "valid_combined_emb=torch.load('/exports/eddie/scratch/s2550585/rating/data/valid_combined_emb.pt')\n",
    "valid_ratings=torch.load('/exports/eddie/scratch/s2550585/rating/data/valid_ratings.pt')\n",
    "\n",
    "train_dataset = UserItemDataset(train_combined_emb, train_ratings)\n",
    "val_dataset = UserItemDataset(valid_combined_emb, valid_ratings)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "input_size = train_combined_emb.shape[1]\n",
    "model = RatingModel(input_size).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "saving_path = '/exports/eddie/scratch/s2550585/rating/data'\n",
    "\n",
    "best_score = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for embeddings, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        embeddings = embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    true_ratings = []\n",
    "    predicted_ratings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in val_dataloader:\n",
    "            embeddings = embeddings.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(embeddings)\n",
    "            predicted = outputs\n",
    "\n",
    "            true_ratings.extend(labels.cpu().numpy())\n",
    "            predicted_ratings.extend(predicted.cpu().numpy())\n",
    "\n",
    "    true_ratings = np.array(true_ratings)\n",
    "    predicted_ratings = np.array(predicted_ratings)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
    "    mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "    current_score = rmse\n",
    "    if current_score < best_score:\n",
    "        best_score = current_score\n",
    "        torch.save(model.state_dict(), os.path.join(saving_path, 'st5_model.pt'))\n",
    "        print(f\"New best model saved with {metric_to_monitor.upper()}: {best_score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
